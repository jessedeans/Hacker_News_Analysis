{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# What and When to Post on Hacker News for Best Interaction\n",
    "\n",
    "[Hacker News](https://news.ycombinator.com/) is a site started by the startup incubator Y Combinator, where user-submitted stories, known as \"posts,\" are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "There are two popular post types on Hacker News, Show HN and Ask HN. Users submit Ask HN posts to ask the Hacker News community a specific question. Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "In this notebook I'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "\n",
    "## Import Data\n",
    "You can find the original data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts). The data I will be working with has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. It can be found in this repository. Below, I'll open the data, store it as a list of lists, and print the first few lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data\n",
    "The dataset has a header row/list. Below I'll remove that list and save it seperatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0] #Store the header list seperatly \n",
    "hn = hn[1:] # Reomve the header list\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've removed the headers from the dataset, I'm ready to filter the data. Since I'm only concerned with post titles beginning with Ask HN or Show HN, I'll create new lists of lists containing just the data for those titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ask posts: 1744\n",
      "Total show posts: 1162\n",
      "Total other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Total ask posts:',len(ask_posts))\n",
    "print('Total show posts:',len(show_posts))\n",
    "print('Total other posts:',len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data\n",
    "Now that I have seperate lists for each type of post, I can determine the average comments for each post type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments for an ask post: 14.04\n",
      "Average comments for a show post: 10.32\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = float(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print('Average comments for an ask post: {:.2f}'.format(avg_ask_comments))\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = float(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print('Average comments for a show post: {:.2f}'.format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Ask HN posts average almost 4 comments more than Show HN posts. Since ask posts are more likely to receive comments, I'll focus the remaining analysis  on these post types.\n",
    "\n",
    "Now, I'll determine if ask posts created at a certain time are more likely to attract comments. Below I'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ask HN posts by hour of day (eastern time)\n",
      "{9: 46, 13: 86, 10: 60, 14: 108, 16: 109, 23: 69, 12: 74, 17: 101, 15: 117, 21: 110, 20: 81, 2: 59, 18: 110, 3: 55, 5: 47, 19: 111, 1: 61, 22: 72, 8: 49, 4: 48, 0: 56, 6: 45, 7: 35, 11: 59}\n",
      "\n",
      "\n",
      "Comments on Ask HN posts by hour of day (eastern time)\n",
      "{9: 257.0, 13: 1282.0, 10: 794.0, 14: 1419.0, 16: 1831.0, 23: 544.0, 12: 691.0, 17: 1147.0, 15: 4478.0, 21: 1749.0, 20: 1724.0, 2: 1384.0, 18: 1441.0, 3: 422.0, 5: 493.0, 19: 1191.0, 1: 716.0, 22: 481.0, 8: 497.0, 4: 340.0, 0: 457.0, 6: 398.0, 7: 269.0, 11: 643.0}\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    num_comments = float(post[4])\n",
    "    result_list.append([created_at,num_comments])\n",
    "\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    date = dt.datetime.strptime(date, '%m/%d/%Y %H:%M' )\n",
    "    hour = date.hour\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "print('Number of Ask HN posts by hour of day (eastern time)')    \n",
    "print(counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print('Comments on Ask HN posts by hour of day (eastern time)')\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll use the the two dictionaires I created to calculate the average number of comments for each hour. Then I'll swap the values in the list so the comments are first. This will make it easy to use the built in sort function to identify the hours with the most comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append(\n",
    "        [hour,(comments_by_hour[hour]/counts_by_hour[hour])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 5.586956521739131],\n",
       " [13, 14.906976744186046],\n",
       " [10, 13.233333333333333],\n",
       " [14, 13.13888888888889],\n",
       " [16, 16.798165137614678],\n",
       " [23, 7.884057971014493],\n",
       " [12, 9.337837837837839],\n",
       " [17, 11.356435643564357],\n",
       " [15, 38.27350427350427],\n",
       " [21, 15.9],\n",
       " [20, 21.28395061728395],\n",
       " [2, 23.45762711864407],\n",
       " [18, 13.1],\n",
       " [3, 7.672727272727273],\n",
       " [5, 10.48936170212766],\n",
       " [19, 10.72972972972973],\n",
       " [1, 11.737704918032787],\n",
       " [22, 6.680555555555555],\n",
       " [8, 10.142857142857142],\n",
       " [4, 7.083333333333333],\n",
       " [0, 8.160714285714286],\n",
       " [6, 8.844444444444445],\n",
       " [7, 7.685714285714286],\n",
       " [11, 10.898305084745763]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    time = row[0]\n",
    "    avg = row[1]\n",
    "    swap_avg_by_hour.append([avg,time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.586956521739131, 9],\n",
       " [14.906976744186046, 13],\n",
       " [13.233333333333333, 10],\n",
       " [13.13888888888889, 14],\n",
       " [16.798165137614678, 16],\n",
       " [7.884057971014493, 23],\n",
       " [9.337837837837839, 12],\n",
       " [11.356435643564357, 17],\n",
       " [38.27350427350427, 15],\n",
       " [15.9, 21],\n",
       " [21.28395061728395, 20],\n",
       " [23.45762711864407, 2],\n",
       " [13.1, 18],\n",
       " [7.672727272727273, 3],\n",
       " [10.48936170212766, 5],\n",
       " [10.72972972972973, 19],\n",
       " [11.737704918032787, 1],\n",
       " [6.680555555555555, 22],\n",
       " [10.142857142857142, 8],\n",
       " [7.083333333333333, 4],\n",
       " [8.160714285714286, 0],\n",
       " [8.844444444444445, 6],\n",
       " [7.685714285714286, 7],\n",
       " [10.898305084745763, 11]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask Post Comments\n",
      "15:00 : 38.27 comments\n",
      "02:00 : 23.46 comments\n",
      "20:00 : 21.28 comments\n",
      "16:00 : 16.80 comments\n",
      "21:00 : 15.90 comments\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print('Top 5 hours for Ask Post Comments')\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = str(row[1])\n",
    "    avg_n = row[0]\n",
    "    hour_dt = dt.datetime.strptime(hour, '%H')\n",
    "    hour_dt = hour_dt.strftime('%H:00')\n",
    "    output = ': {:.2f} comments'.format(avg_n)\n",
    "    print(hour_dt,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    " In this project, I analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on my analysis, to maximize the amount of comments a post receives, I'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est).\n",
    "\n",
    "However, it should be noted that the data set I analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments on average.\n",
    "\n",
    "## Shoutouts\n",
    "This notebook is based on a guided project from [Dataquest.io](https://www.dataquest.io/), an online platform to learn Data Analysis and Data Science. The learning goal of the project was to review working with strings, dates and times, and object-oriented programming."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
